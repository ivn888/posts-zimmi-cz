<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
<channel>
	<title>Michal Zimmermann</title>
	<link>http://zimmi.cz/posts</link>
	<lastBuildDate>Mon, 23 Feb 2015 15:15:05 +0100</lastBuildDate>
	<pubDate>Mon, 23 Feb 2015 15:15:05 +0100</pubDate>
	<description>Pieces of knowledge from the world of GIS.</description>
		<item>
		<title>Hosting Website On Openshift</title>
		<link>http://zimmi.cz/posts/posts/2015/hosting-website-on-openshift/</link>
		<pubDate>Mon, 23 Feb 2015 14:25:20 +0100</pubDate>
		<guid>http://zimmi.cz/posts/posts/2015/hosting-website-on-openshift/</guid>
		<description>&lt;p&gt;I decided to migrate &lt;a href=&quot;http://www.zimmi.cz&quot;&gt;my web&lt;/a&gt; to &lt;a href=&quot;http://openshift.com&quot;&gt;OpenShift&lt;/a&gt;. It was a bit frustrating but I got working eventually.&lt;/p&gt;

&lt;h2&gt;Things to know before taking the leap&lt;/h2&gt;

&lt;p&gt;Some domain providers don&amp;#8217;t support CNAME changes for root domains (zimmi.cz in my case). This means you can&amp;#8217;t simply tell your domain to serve content from OpenShift address. But what you can do is to tell your &lt;code&gt;www&lt;/code&gt; subdomain to do so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;www.zimmi.cz CNAME hp-zimmi.rhcloud.com
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which is great until you realize you&amp;#8217;ve just created two different websites. That&amp;#8217;s where &lt;a href=&quot;http://wwwizer.com/&quot;&gt;wwwizer&lt;/a&gt; lends you a hand and lets you redirect your naked domain to your &lt;code&gt;www&lt;/code&gt; domain:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zimmi.cz A 174.129.25.170
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now everything works fine and you have your &lt;code&gt;www.domain.tld&lt;/code&gt; up and running.&lt;/p&gt;

&lt;h2&gt;OpenShift subdomains&lt;/h2&gt;

&lt;p&gt;I wasn&amp;#8217;t successful creating a subdomain on the same application where I run my domain. This can be easily solved by creating another application and pointing DNS to it:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;posts.zimmi.cz A 174.179.25.170
www.posts.zimmi.cz CNAME posts-zimmi.rhcloud.com
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Just don&amp;#8217;t forget to handle both naked and &lt;code&gt;www&lt;/code&gt; version. When Google reindexes new URLs (http://www.zimmi.cz/posts instead of http://posts.zimmi.cz) subdomain application might be deleted.&lt;/p&gt;
</description>
	</item>
		<item>
		<title>PostGIS Case Study: Vozejkmap Open Data (Part II)</title>
		<link>http://zimmi.cz/posts/posts/2015/postgis-case-study-vozejkmap-open-data-part-ii/</link>
		<pubDate>Sat, 21 Feb 2015 20:54:44 +0100</pubDate>
		<guid>http://zimmi.cz/posts/posts/2015/postgis-case-study-vozejkmap-open-data-part-ii/</guid>
		<description>&lt;p&gt;&lt;a href=&quot;/posts/2014/postgis-case-study-vozejkmap-open-data-part-i/&quot;&gt;In the first part of my little case study&lt;/a&gt; I downloaded &lt;a href=&quot;http://vozejkmap.cz&quot;&gt;vozejkmap.cz&lt;/a&gt; dataset and imported it into the PostGIS database. Having spatial data safely stored the time comes to get it onto the map. Libraries used are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://leafletjs.com&quot;&gt;Leaflet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/lvoogdt/Leaflet.awesome-markers&quot;&gt;Leaflet.awesome-markers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/Leaflet/Leaflet.markercluster&quot;&gt;Leaflet.markercluster&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I teach cartography visualization classes this semester and this map should serve well as an example of what can be done with online maps.&lt;/p&gt;

&lt;h2&gt;Retrieving data from the PostGIS database&lt;/h2&gt;

&lt;p&gt;Our goal is to build the whole map as a static HTML page without any backend logic. Thus, data needs to be extracted from the database into the format readable with Leaflet - &lt;a href=&quot;http://geojson.org/&quot;&gt;GeoJSON&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;That&amp;#8217;s fairly easy with the &lt;a href=&quot;http://www.postgresonline.com/journal/archives/267-Creating-GeoJSON-Feature-Collections-with-JSON-and-PostGIS-functions.html&quot;&gt;postgresonline.com tutorial&lt;/a&gt;. It took me quite a time to find out what the following query does. Splitting it into smaller chunks helped a lot.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT row_to_json(fc)
FROM (
SELECT &#039;FeatureCollection&#039; AS type,
    array_to_json(array_agg(f)) AS features
    FROM (SELECT &#039;Feature&#039; AS type,
        ST_AsGeoJSON(lg.geom)::json As geometry,
        row_to_json((SELECT l FROM (SELECT id, title, location_type, description, author_name, attr1, attr2, attr3) AS l
  )) AS properties
FROM vozejkmap AS lg ) AS f )  AS fc \g /path/to/file.json;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To get all rows with &lt;code&gt;type&lt;/code&gt;, &lt;code&gt;geometry&lt;/code&gt; and &lt;code&gt;properties&lt;/code&gt; columns (these are the ones defined in GeoJSON specification, see the link above), run this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT &#039;Feature&#039; AS type,
            ST_AsGeoJSON(lg.geom)::json As geometry,
            row_to_json((SELECT l FROM (SELECT id, title, location_type, description, author_name, attr1, attr2, attr3) AS l
      )) AS properties
    FROM vozejkmap AS lg
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;array_agg()&lt;/code&gt; squashes all the rows into an array while &lt;code&gt;array_to_json()&lt;/code&gt; returns the array as JSON.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT &#039;FeatureCollection&#039; AS type,
    array_to_json(array_agg(f)) AS features
    FROM (SELECT &#039;Feature&#039; AS type,
        ST_AsGeoJSON(lg.geom)::json As geometry,
        row_to_json((SELECT l FROM (SELECT id, title, location_type, description, author_name, attr1, attr2, attr3) AS l
  )) AS properties
FROM vozejkmap AS lg ) AS f
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the last step (the whole code as shown above) &lt;code&gt;row_to_json&lt;/code&gt; returns the result as JSON.&lt;/p&gt;

&lt;h3&gt;Caveats&lt;/h3&gt;

&lt;p&gt;If you run this code from the psql console, be sure you&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;set &lt;em&gt;show only row&lt;/em&gt; to true with &lt;code&gt;\t&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;set &lt;em&gt;expanded output&lt;/em&gt; to false with &lt;code&gt;\x off&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you don&amp;#8217;t, you&amp;#8217;ll have lots of hyphens and column names saved to the json file.&lt;/p&gt;

&lt;h2&gt;Leaflet map&lt;/h2&gt;

&lt;p&gt;Map JavaScript is rather simple with ~30 lines of code (not taking styles into account). Thanks to the great plugins it is easy to show ~7,600 points on the map real quick.&lt;/p&gt;

&lt;p&gt;I didn&amp;#8217;t do much customization apart from styling markers and binding popups.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/posts/2015/postgis-case-study-vozejkmap-open-data-part-ii/map.png&quot; title=&quot;vozejkmap.cz data map&quot; class=&quot;img-responsive centered&quot;&gt;&lt;/p&gt;

&lt;h2&gt;What&amp;#8217;s next&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;http://turfjs.org&quot;&gt;Turf&lt;/a&gt; which means I need to think of what could be fun to do with this data&lt;/li&gt;
&lt;li&gt;Layers switching&lt;/li&gt;
&lt;li&gt;Map key (by extending L.Control)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The code is still &lt;a href=&quot;https://github.com/zimmicz/vozejkmap-to-postgis&quot;&gt;available at my GitHub&lt;/a&gt;.&lt;/p&gt;
</description>
	</item>
		<item>
		<title>Using PostgreSQL To Update Outdated Map Links</title>
		<link>http://zimmi.cz/posts/posts/2015/using-postgresql-to-update-outdated-map-links/</link>
		<pubDate>Mon, 16 Feb 2015 18:38:57 +0100</pubDate>
		<guid>http://zimmi.cz/posts/posts/2015/using-postgresql-to-update-outdated-map-links/</guid>
		<description>&lt;p&gt;&lt;a href=&quot;http://www.edpp.cz/pdb_mapa-povodnoveho-planu-mesta/&quot;&gt;We&amp;#8217;ve rolled out&lt;/a&gt; completely new map GUI at &lt;a href=&quot;http://edpp.cz&quot;&gt;edpp.cz&lt;/a&gt; built on top of &lt;a href=&quot;http://ol3js.org&quot;&gt;OpenLayers 3&lt;/a&gt;. It looks great and has lots of functions both for BFU and power users. The only pitfall that came with moving away from OpenLayers 2 were remarkable differences in zoom levels between the old map and the new one.&lt;/p&gt;

&lt;p&gt;Each of our maps is defined by our admins (center, zoom level, layers) at the map creation. Lots of links calling different views of map are created as well. They take form of &lt;code&gt;http://edpp.cz/some-map?0=0&amp;amp;1=0...zoom=5&lt;/code&gt;. That &lt;code&gt;zoom=&amp;lt;Number&amp;gt;&lt;/code&gt; started causing troubles immediately after the map switch. No way my workmates would update them one by one as there were ~4,500 of them. Sounds like a task for little bit of regular expressions and some SQL updates.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;UPDATE table
    SET column = regexp_replace(column, &#039;zoom=\d&#039;, &#039;zoom=&#039; || subquery.zoom, &#039;g&#039;)
    FROM (
        SELECT regexp_replace(
            substring(column from &#039;zoom=\d&#039;),
            &#039;zoom=(\d)&#039;,
            &#039;\1&#039;,
            &#039;g&#039;)::integer + 2 AS zoom, guid
        FROM table) AS subquery
    WHERE column ~ &#039;zoom=\d&#039;
        AND table.guid = subquery.guid
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;#8217;s what I&amp;#8217;ve come up with. It basically extracts the zoom level from the link, adds number two to its value and writes it back to the string.&lt;/p&gt;
</description>
	</item>
		<item>
		<title>Leaflet With Custom CRS (EPSG:5514)</title>
		<link>http://zimmi.cz/posts/posts/2015/leaflet-with-custom-crs-epsg-5514/</link>
		<pubDate>Thu, 15 Jan 2015 19:46:22 +0100</pubDate>
		<guid>http://zimmi.cz/posts/posts/2015/leaflet-with-custom-crs-epsg-5514/</guid>
		<description>&lt;p&gt;If you ever find yourself in need to use custom projection with Leaflet, feel free to start with this example of &lt;a href=&quot;https://github.com/zimmicz/leaflet-custom-crs-jtsk&quot;&gt;Czech national coordinate system&lt;/a&gt;. All you need is &lt;a href=&quot;http://leafletjs.com&quot;&gt;Leaflet&lt;/a&gt;, &lt;a href=&quot;http://proj4js.org/&quot;&gt;proj4.js&lt;/a&gt; and &lt;a href=&quot;https://github.com/kartena/Proj4Leaflet&quot;&gt;proj4 for Leaflet plugin&lt;/a&gt;. I&amp;#8217;m still not sure how &lt;code&gt;origin&lt;/code&gt; coordinates work though.&lt;/p&gt;
</description>
	</item>
		<item>
		<title>PostGIS Case Study: VozejkMap Open Data (Part I)</title>
		<link>http://zimmi.cz/posts/posts/2014/postgis-case-study-vozejkmap-open-data-part-i/</link>
		<pubDate>Tue, 02 Dec 2014 17:59:40 +0100</pubDate>
		<guid>http://zimmi.cz/posts/posts/2014/postgis-case-study-vozejkmap-open-data-part-i/</guid>
		<description>&lt;p&gt;&lt;a href=&quot;http://www.vozejkmap.cz&quot;&gt;VozejkMap.cz&lt;/a&gt; is a Czech &lt;strong&gt;open data&lt;/strong&gt; iniatitive that collects data about wheelchair accessible places, e.g. pubs, toilets, cafes etc. As part of being open, they offer a &lt;a href=&quot;http://www.vozejkmap.cz/opendata/&quot;&gt;JSON data download&lt;/a&gt;. JSON is a great text format, not so great spatial format (leaving GeoJSON aside) though. Anyway, nothing that &lt;a href=&quot;http://posts.zimmi.cz/tag/postgis/&quot;&gt;PostGIS&lt;/a&gt; wouldn&amp;#8217;t be able to take care of.&lt;/p&gt;

&lt;h3&gt;Let&amp;#8217;s get some data&lt;/h3&gt;

&lt;p&gt;Using curl or wget, let&amp;#8217;s download the JSON file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget -O /tmp/locations.json http://www.vozejkmap.cz/opendata/locations.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We need to split them into rows to load each point into one row:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sed -i &#039;s/\},{/\n},{/g&#039; /tmp/locations.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you peep into the file, you&amp;#8217;ll see lots of unicode characters we don&amp;#8217;t want to have in our pretty little table. Here&amp;#8217;s how we get rid of them:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo -en &quot;$(cat /tmp/locations.json)&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Let&amp;#8217;s load the data&lt;/h3&gt;

&lt;p&gt;Let&amp;#8217;s just be nice and leave the public schema clean.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE SCHEMA vozejkmap;
SET search_path=vozejkmap, public;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Load the data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE TABLE vozejkmap_raw(id SERIAL PRIMARY KEY, raw text);
COPY vozejkmap_raw(raw) FROM &#039;/tmp/locations.json&#039; DELIMITERS &#039;#&#039; ESCAPE &#039;\&#039; CSV;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A few notes:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;I&amp;#8217;m using &lt;code&gt;/tmp&lt;/code&gt; folder to avoid any permission-denied issues when opening the file from &lt;code&gt;psql&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;By setting &lt;code&gt;DELIMITERS&lt;/code&gt; to &lt;code&gt;#&lt;/code&gt; we tell PostgreSQL to load whole data into one column, because it is safe to assume there is no such character in our data.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ESCAPE&lt;/code&gt; needs to be set because there is one trailing quote in the dataset.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;Let&amp;#8217;s get dirty with spatial data&lt;/h3&gt;

&lt;p&gt;Great, now what? We loaded all the data into one column. That is not very useful, is it? How about splitting them into separate columns with this query? Shall we call it a &lt;code&gt;split_part&lt;/code&gt; hell?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE TABLE vozejkmap AS
SELECT
    id,
    trim(
        split_part(
            split_part(
                raw, &#039;title:&#039;, 2
            ),
            &#039;,location_type:&#039;, 1
        )
    ) AS title,

    trim(
        split_part(
            split_part(
                raw, &#039;location_type:&#039;, 2
            ),
            &#039;,description:&#039;, 1
        )
    )::integer AS location_type,

    trim(
        split_part(
            split_part(
                raw, &#039;description:&#039;, 2
            ),
            &#039;,lat:&#039;, 1
        )
    ) AS description,

    cast( trim(
        split_part(
            split_part(
                raw, &#039;lat:&#039;, 2
            ),
            &#039;,lng:&#039;, 1
        )
    ) AS double precision) AS lat,

    cast( trim(
        split_part(
            split_part(
                raw, &#039;lng:&#039;, 2
            ),
            &#039;,attr1:&#039;, 1
        )
    )  AS double precision) AS lng,

    trim(
        split_part(
            split_part(
                raw, &#039;attr1:&#039;, 2
            ),
            &#039;,attr2:&#039;, 1
        )
    )::integer AS attr1,

    trim(
        split_part(
            split_part(
                raw, &#039;attr2:&#039;, 2
            ),
            &#039;,attr3:&#039;, 1
        )
    ) AS attr2,

    trim(
        split_part(
            split_part(
                raw, &#039;attr3:&#039;, 2
            ),
            &#039;,author_name:&#039;, 1
        )
    ) AS attr3,

    trim(
        split_part(
            split_part(
                raw, &#039;author_name:&#039;, 2
            ),
            &#039;,}:&#039;, 1
        )
    ) AS author_name

FROM vozejkmap_raw;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It just splits the JSON data and creates table out of it according to the &lt;a href=&quot;http://www.vozejkmap.cz/opendata/&quot;&gt;VozejkMap.cz data specification&lt;/a&gt;. Before going on we should create a table with location types to join their numeric codes to real names:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE TABLE location_type (
    id integer PRIMARY KEY,
    description varchar(255)
);

INSERT INTO location_type VALUES(1, &#039;Kultura&#039;);
INSERT INTO location_type VALUES(2, &#039;Sport&#039;);
INSERT INTO location_type VALUES(3, &#039;Instituce&#039;);
INSERT INTO location_type VALUES(4, &#039;Jídlo a pití&#039;);
INSERT INTO location_type VALUES(5, &#039;Ubytování&#039;);
INSERT INTO location_type VALUES(6, &#039;Lékaři, lékárny&#039;);
INSERT INTO location_type VALUES(7, &#039;Jiné&#039;);
INSERT INTO location_type VALUES(8, &#039;Doprava&#039;);
INSERT INTO location_type VALUES(9, &#039;Veřejné WC&#039;);
INSERT INTO location_type VALUES(10, &#039;Benzínka&#039;);
INSERT INTO location_type VALUES(11, &#039;Obchod&#039;);
INSERT INTO location_type VALUES(12, &#039;Banka, bankomat&#039;);
INSERT INTO location_type VALUES(13, &#039;Parkoviště&#039;);
INSERT INTO location_type VALUES(14, &#039;Prodejní a servisní místa Škoda Auto&#039;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;#8217;s build some geometry column, constraints and indexes. And don&amp;#8217;t forget to get rid of all the mess (the &lt;code&gt;vozejkmap_raw&lt;/code&gt; table).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;DROP TABLE vozejkmap_raw;
ALTER TABLE vozejkmap ADD PRIMARY KEY(id);
-- 4326 geometry is not very useful for measurements, I might get to that next time
ALTER TABLE vozejkmap ADD COLUMN geom geometry(point, 4326);
ALTER TABLE vozejkmap ADD CONSTRAINT loctype_fk FOREIGN KEY(location_type); REFERENCES location_type(id);

UPDATE vozejkmap SET geom = ST_SetSRID(ST_MakePoint(lng, lat), 4326);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;And here we are, ready to use our spatial data!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Feel free to &lt;a href=&quot;https://github.com/zimmicz/vozejkmap-to-postgis&quot;&gt;grab the code&lt;/a&gt; at GitHub.&lt;/p&gt;
</description>
	</item>
		<item>
		<title>PostGIS Spatial Indexing With ST_Intersects</title>
		<link>http://zimmi.cz/posts/posts/2014/postgis-spatial-indexing-with-st-intersects/</link>
		<pubDate>Sun, 23 Nov 2014 10:05:41 +0100</pubDate>
		<guid>http://zimmi.cz/posts/posts/2014/postgis-spatial-indexing-with-st-intersects/</guid>
		<description>&lt;p&gt;&lt;a href=&quot;http://postgis.net/docs/ST_Intersects.html&quot;&gt;PostGIS docs&lt;/a&gt; clearly states that:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This function call will automatically include a bounding box comparison that will make use of any indexes that are available on the geometries.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That means (or at least I think so) that you shouldn&amp;#8217;t bother with using &lt;a href=&quot;http://postgis.net/docs/reference.html#Operators&quot;&gt;operators&lt;/a&gt; before calling this function.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://slides.com/michalzimmermann&quot;&gt;I was preparing&lt;/a&gt; my second lecture on PostGIS and I was experimenting a bit and came up with an interesting thing on this matter:&lt;/p&gt;

&lt;p&gt;Let&amp;#8217;s have two SQL relations, &lt;code&gt;roads&lt;/code&gt; and &lt;code&gt;regions&lt;/code&gt;. I would like to retrieve every road that intersects a certain region. Spatial indexes were built beforehand on both tables.&lt;/p&gt;

&lt;p&gt;First try:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;EXPLAIN ANALYZE SELECT roads.* FROM roads
JOIN regions ON ST_Intersects(roads.geom, regions.geom)
WHERE regions.&quot;NAZEV&quot; = &#039;Jihomoravský&#039;;`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And here comes the result:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Nested Loop  (cost=4.85..324.26 rows=249 width=214) (actual time=45.102..5101.472 rows=74253 loops=1)
-&amp;gt;  Seq Scan on regions  (cost=0.00..12.62 rows=1 width=32) (actual time=0.015..0.018 rows=1 loops=1)
     Filter: ((&quot;NAZEV&quot;)::text = &#039;Jihomoravský&#039;::text)
     Rows Removed by Filter: 13
-&amp;gt;  Bitmap Heap Scan on roads  (cost=4.85..311.38 rows=25 width=214) (actual time=45.079..4931.495 rows=74253 loops=1)
     Recheck Cond: (geom &amp;amp;&amp;amp; regions.geom)
     Rows Removed by Index Recheck: 154841
     Filter: _st_intersects(geom, regions.geom)
     Rows Removed by Filter: 71212
     -&amp;gt;  Bitmap Index Scan on roads_idx  (cost=0.00..4.85 rows=75 width=0) (actual time=40.142..40.142 rows=145465 loops=1)
           Index Cond: (geom &amp;amp;&amp;amp; regions.geom)
Total runtime: 5181.459 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I was pretty satisfied with the result, I kept digging deeper though.&lt;/p&gt;

&lt;p&gt;Second try:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;EXPLAIN ANALYZE SELECT roads.* FROM roads
JOIN regions ON roads.geom &amp;amp;&amp;amp; regions.geom
WHERE regions.&quot;NAZEV&quot; = &#039;Jihomoravský&#039; AND ST_Intersects(roads.geom, regions.geom);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And the result:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Nested Loop  (cost=0.29..21.19 rows=1 width=214) (actual time=3.041..3850.302 rows=74253 loops=1)
-&amp;gt;  Seq Scan on regions  (cost=0.00..12.62 rows=1 width=32) (actual time=0.021..0.024 rows=1 loops=1)
     Filter: ((&quot;NAZEV&quot;)::text = &#039;Jihomoravský&#039;::text)
     Rows Removed by Filter: 13
-&amp;gt;  Index Scan using roads_idx on roads  (cost=0.29..8.55 rows=1 width=214) (actual time=2.938..3681.432 rows=74253 loops=1)
     Index Cond: ((geom &amp;amp;&amp;amp; regions.geom) AND (geom &amp;amp;&amp;amp; regions.geom))
     Filter: _st_intersects(geom, regions.geom)
     Rows Removed by Filter: 71212
Total runtime: 3930.270 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now there&amp;#8217;s a significant difference between total runtimes of both queries and - more important - also a difference between their query plans. The latter is like &lt;strong&gt;20 % faster&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;I&amp;#8217;m puzzled about this behavior and would appreciate any thoughts on this. Reach me at &lt;a href=&quot;http://twitter.com/zimmicz&quot;&gt;Twitter&lt;/a&gt;, &lt;a href=&quot;https://www.linkedin.com/pub/michal-zimmermann/29/8/b30&quot;&gt;LinkedIn&lt;/a&gt; or e-mail (zimmicz[at]gmail.com).&lt;/p&gt;
</description>
	</item>
		<item>
		<title>Bash: Prepend To Filename</title>
		<link>http://zimmi.cz/posts/posts/2014/bash-prepend-to-filename/</link>
		<pubDate>Sat, 01 Nov 2014 13:11:29 +0100</pubDate>
		<guid>http://zimmi.cz/posts/posts/2014/bash-prepend-to-filename/</guid>
		<description>&lt;pre&gt;&lt;code&gt;for f in *; do mv &quot;$f&quot; &quot;prepend_$f&quot;; done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Whenever you need to prepend anything to your files.&lt;/p&gt;
</description>
	</item>
		<item>
		<title>Migrating Geoserver And Checking For Missing Data</title>
		<link>http://zimmi.cz/posts/posts/2014/migrating-geoserver-and-checking-for-missing-data/</link>
		<pubDate>Wed, 29 Oct 2014 16:25:11 +0100</pubDate>
		<guid>http://zimmi.cz/posts/posts/2014/migrating-geoserver-and-checking-for-missing-data/</guid>
		<description>&lt;p&gt;I&amp;#8217;ve upgraded a handful of Geoserver installations and it has never been flawless. If you&amp;#8217;re lucky you end up with just &lt;em&gt;some&lt;/em&gt; layers missing, if you&amp;#8217;re not, you&amp;#8217;ll miss a bunch of them (together with layergroups, some stores, workspaces might screw up etc.).&lt;/p&gt;

&lt;p&gt;But how do you check for missing data before switching to the newer version? Thanks to the &lt;a href=&quot;http://docs.geoserver.org/stable/en/user/rest/api/index.html&quot;&gt;REST API implemented within Geoserver&lt;/a&gt;, it&amp;#8217;s rather easy.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import requests
from bs4 import BeautifulSoup
from requests.auth import HTTPBasicAuth

req = requests.get(&#039;http://example.com/geoserver/rest/layers&#039;, auth=HTTPBasicAuth(&#039;username&#039;, &#039;password&#039;))

html = BeautifulSoup(req.text)
i = 0
for link in html.find_all(&#039;a&#039;):
    i += 1
    href = link.get_text()
    print i

with open(&#039;list.txt&#039;, &#039;a&#039;) as f:
        f.write(href)
        f.write(&#039;\n&#039;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We needed to migrate ~ 17,000 layers last week, and yes, we could have just shut the door and spend couple of nights checking one after another, if we were the dumbest GIS company ever.&lt;/p&gt;

&lt;p&gt;As I wanted to make it a bit easier I wrote the simple Python script (see above) that just authenticates against Geoserver and downloads the list of layers. I actually had to do that twice - both old and new instance. A &lt;a href=&quot;https://www.diffchecker.com/&quot;&gt;simple file comparison&lt;/a&gt; followed and I got a list of missing layers in less than two minutes.&lt;/p&gt;

&lt;p&gt;If you do the same to workspaces, stores and layergroups, your chances of not losing some data after the switch are pretty high.&lt;/p&gt;

&lt;p&gt;I guess it&amp;#8217;s reasonable to check your maps by hand as well, but this gives you the picture of the current state of your data real quick.&lt;/p&gt;
</description>
	</item>
		<item>
		<title>ogr2ogr UNIX x Windows</title>
		<link>http://zimmi.cz/posts/posts/2014/ogr2ogr-unix-x-windows/</link>
		<pubDate>Tue, 23 Sep 2014 20:03:03 +0200</pubDate>
		<guid>http://zimmi.cz/posts/posts/2014/ogr2ogr-unix-x-windows/</guid>
		<description>&lt;p&gt;GDAL with its ogr2ogr, ogrinfo and many more is one of the best open source tools to do anything to your spatial data. It is a&amp;nbsp;command line tool, which sort of determines it to be used with UNIX systems, but you might bump into a Windows guy trying to use it as well once in a while.&lt;/p&gt;

&lt;p&gt;Be careful, it behaves differently on different OS. Let&amp;#8217;s say you do something like this on UNIX:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ogr2ogr -f GeoJSON -where &quot;attribute IN (&#039;value1&#039;, &#039;value2&#039;)&quot; output.json input.json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What you &lt;abbr title=&quot;But you might get expected result as well&quot;&gt;might get is a big nothing&lt;/abbr&gt;. Executed on Windows it gives you the result you&amp;#8217;ve expected. &lt;em&gt;Aargh&lt;/em&gt;, what is that supposed to mean?&lt;/p&gt;

&lt;p&gt;Well, that&amp;#8217;s the ogr2ogr&amp;#8217;s way to tell you: &lt;em&gt;Hello there, you need to switch single quotes for double quotes and vice versa, you dumb!&lt;/em&gt; I don&amp;#8217;t know why and I find it really annoying. Just in case you get stuck with ogr2ogr (or probably any other command line tool), try this.&lt;/p&gt;
</description>
	</item>
		<item>
		<title>Notify When Average of 10 Subsequent Numbers Is Bigger Than Given Value</title>
		<link>http://zimmi.cz/posts/posts/2014/notify-when-average-of-10-subsequent-numbers-is-bigger-than-given-value/</link>
		<pubDate>Sun, 21 Sep 2014 17:38:29 +0200</pubDate>
		<guid>http://zimmi.cz/posts/posts/2014/notify-when-average-of-10-subsequent-numbers-is-bigger-than-given-value/</guid>
		<description>&lt;p&gt;I found an &lt;a href=&quot;http://stackoverflow.com/questions/25952380/php-find-a-maximum-average-for-10-subsequent-numbers-in-a-list-of-50-random-numb&quot;&gt;interesting question&lt;/a&gt; at StackOverflow asking for help finding solution to what I have already mentioned in the title, with PHP. I gave it a try before reading answers and came up with the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$avg  = // value we are looking for
$size = count($numbers);

for ($i = 0; $i &amp;lt; $size; $i += 1) {
    if ($i + 9 &amp;lt; 51) {
        $val += $numbers[$i];
        for ($j = $i + 1; $j &amp;lt; 10 + $i; $j += 1) {
            $val += $numbers[$j];
        }
        if ($val / 10 &amp;gt;= $avg) { // hit
            // do something
        }
        $val = 0;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That was the first that I could think of. And it worked. The answer given by Dave Chen was much more elegant than my solution (although I think it does something a bit different, but that&amp;#8217;s not the point here):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$number = 10; //numbers in a set
$max = 0;
$index = 0;

$size = sizeof($numbers) - $number;
for ($i = 0; $i &amp;lt; $size; $i++) {
    $tmp = array_sum(array_slice($numbers, $i, $number)) / $number;
    if ($tmp &amp;gt; $max) {
        $max = $tmp;
        $index = $i;
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I made a simple benchmark with &lt;a href=&quot;http://php.net/manual/en/function.microtime.php&quot;&gt;&lt;code&gt;microtime()&lt;/code&gt;&lt;/a&gt; and found out that my solution (ran 100k times) took about ~12.3 seconds while Dave&amp;#8217;s took only ~7.4 seconds to finish. That makes his code almost twice faster than mine.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lesson learned: do not stop learning!&lt;/strong&gt;&lt;/p&gt;
</description>
	</item>
	</channel>
</rss>